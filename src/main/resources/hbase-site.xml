<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
     /**
 *
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
-->
<configuration>
    <property>
        <name>hfile.format.version</name>
        <value>3</value>
    </property>

    <property>
        <name>hbase.rootdir</name>
        <value>hdfs://sensetime-data-hadoop-video/data/hbase</value>
        <description>The directory shared by RegionServers.
        </description>
    </property>

    <property>
        <name>hbase.cluster.distributed</name>
        <value>true</value>
        <description>The mode the cluster will be in. Possible values are
            false: standalone and pseudo-distributed setups with managed Zookeeper
            true: fully-distributed with unmanaged Zookeeper Quorum (see hbase-env.sh)
        </description>
    </property>


  <property>
    <name>ha.zookeeper.auth</name>
    <value>@/usr/local/hadoop/etc/hadoop/zk-auth.txt</value>
  </property>
  <property>
    <name>ha.zookeeper.acl</name>
    <value>@/usr/local/hadoop/etc/hadoop/zk-acl.txt</value>
  </property>

    <property>
        <name>hbase.zookeeper.quorum</name>
        <value>node-00.hadoop-video.data.sensetime.com:2181,node-01.hadoop-video.data.sensetime.com:2181,node-02.hadoop-video.data.sensetime.com:2181/hbasebig</value>
    </property>

    <property>
        <name>hbase.tmp.dir</name>
        <value>/data/hadoop/hbase/tmp/</value>
        <description>Temporary directory on the local filesystem. Change this setting to point to a location more
            permanent than '/tmp', the usual resolve for java.io.tmpdir, as the '/tmp' directory is cleared on machine
            restart.
        </description>
    </property>


    <property>
        <name>hbase.bulkload.staging.dir</name>
        <value>/tmp/hbase-staging</value>
    </property>

    <property>
        <name>hbase.security.authorization</name>
        <value>true</value>
    </property>

    <property>
        <name>hbase.security.authentication</name>
        <value>kerberos</value>
        <description>The Kerberos keytab file to use for SPNEGO authentication by the web server.</description>
    </property>

    <property>
        <name>hbase.master.kerberos.principal</name>
        <value>hbase/_HOST@HADOOP-VIDEO.DATA.SENSETIME.COM</value>
        <description>Ex. "hbase/_HOST@EXAMPLE.COM". The kerberos principal name that should be used to run the HMaster
            process. The principal name should be in the form: user/hostname@DOMAIN. If "_HOST" is used as the hostname
            portion, it will be replaced with the actual hostname of the running instance.
        </description>
    </property>

    <property>
        <name>hbase.master.keytab.file</name>
        <value>/etc/security/keytab/hbase.keytab</value>
        <description>Full path to the kerberos keytab file to use for logging in the configured HMaster server
            principal.
        </description>
    </property>

    <property>
        <name>hbase.regionserver.kerberos.principal</name>
        <value>hbase/_HOST@HADOOP-VIDEO.DATA.SENSETIME.COM</value>
        <description>Ex. "hbase/_HOST@EXAMPLE.COM". The kerberos principal name that should be used to run the
            HRegionServer process. The principal name should be in the form: user/hostname@DOMAIN. If "_HOST" is used as
            the hostname portion, it will be replaced with the actual hostname of the running instance. An entry for
            this principal must exist in the file specified in hbase.regionserver.keytab.file
        </description>
    </property>

    <property>
        <name>hbase.regionserver.keytab.file</name>
        <value>/etc/security/keytab/hbase.keytab</value>
        <description>Full path to the kerberos keytab file to use for logging in the configured HRegionServer server
            principal.
        </description>
    </property>
    <property>
        <name>hbase.superuser</name>
        <value>hbase</value>
        <description>List of users or groups (comma-separated), who are allowed full privileges, regardless of stored
            ACLs, across the cluster. Only used when HBase security is enabled.
        </description>
    </property>
    
    <property>
        <name>hbase.security.authentication.spnego.kerberos.principal</name>
        <value>HTTP/_HOST@HADOOP-VIDEO.DATA.SENSETIME.COM</value>
        <description>Required for SPNEGO, the Kerberos principal to use for SPNEGO authentication by the
            web server. The _HOST keyword will be automatically substituted with the node's
            hostname.
        </description>
    </property>

    <property>
        <name>hbase.security.authentication.spnego.kerberos.keytab</name>
        <value>/etc/security/keytab/hbase.keytab</value>
        <description>Required for SPNEGO, the Kerberos keytab file to use for SPNEGO authentication by the
            web server.
        </description>
    </property>

    <property>
        <name>hadoop.security.authorization</name>
        <value>ture</value>
    </property>

    <property>
        <name>hbase.security.exec.permission.checks</name>
        <value>true</value>
    </property>
    <property>
        <name>hbase.hregion.majorcompaction</name>
        <value>0</value>
    </property>

<property>
    <name>hbase.coprocessor.region.classes</name>    
    <value>org.apache.hadoop.hbase.security.access.AccessController</value>  
</property>
  <property>
    <name>hbase.coprocessor.master.classes</name>
    <value>org.apache.hadoop.hbase.security.access.AccessController</value>
  </property>
  <property>
    <name>hbase.rpc.engine</name>
    <value>org.apache.hadoop.hbase.ipc.SecureRpcEngine</value>
  </property>

<property>
  <name>hbase.thrift.keytab.file</name>
  <value>/etc/security/keytab/hbase.keytab</value>
</property>
<property>
  <name>hbase.thrift.kerberos.principal</name>
  <value>hbase/_HOST@HADOOP-VIDEO.DATA.SENSETIME.COM</value>
</property>
<property>
  <name>hbase.thrift.security.qop</name>
  <value>authentication</value>
</property>

<property>
  <name>hadoop.proxyuser.hbase.groups</name>
  <value>*</value>
</property>
<property>
  <name>hadoop.proxyuser.hbase.hosts</name>
  <value>*</value>
</property>
<property>
  <name>hbase.regionserver.thrift.http</name>
  <value>false</value>
</property>
<property>
  <name>hbase.thrift.support.proxyuser</name>
  <value>true</value>
</property>

<property>
  <name>hbase.rest.authentication.type</name>
  <value>kerberos</value>
</property>
<property>
  <name>hbase.rest.authentication.kerberos.principal</name>
  <value>HTTP/_HOST@HADOOP-VIDEO.DATA.SENSETIME.COM</value>
</property>
<property>
  <name>hbase.rest.authentication.kerberos.keytab</name>
  <value>/etc/security/keytab/thrift_server.keytab</value>
</property>


<property>
  <name>phoenix.functions.allowUserDefinedFunctions</name>
  <value>true</value>
</property>
<property>
  <name>fs.hdfs.impl</name>
  <value>org.apache.hadoop.hdfs.DistributedFileSystem</value>
</property>
<property>
  <name>hbase.dynamic.jars.dir</name>
  <value>${hbase.rootdir}/lib</value>
  <description>
    The directory from which the custom udf jars can be loaded
    dynamically by the phoenix client/region server without the need to restart. However,
    an already loaded udf class would not be un-loaded. See
    HBASE-1936 for more details.
  </description>
</property>
<property>
      <name>phoenix.query.timeoutMs</name>
      <value>60000</value>
    </property>

    <property>
      <name>phoenix.schema.isNamespaceMappingEnabled</name>
      <value>true</value>
    </property>

    <property>
      <name>phoenix.schema.mapSystemTablesToNamespace</name>
      <value>true</value>
    </property>

</configuration>
